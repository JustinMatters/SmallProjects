{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fe9c66",
   "metadata": {},
   "source": [
    " # Image categoriser\n",
    " \n",
    " A proof of concept for a zero-shot photograph categoriser using OpenAI's gpt-4-vision-preview VLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27756a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import at the library level to avoid function name confusion between libraries for simplicity\n",
    "import base64\n",
    "import datetime\n",
    "import fnmatch\n",
    "import functools\n",
    "import json\n",
    "import openai\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our requirements for classification\n",
    "folder_to_classify = \"D:/pictures\"\n",
    "style_categories = [\"Photo\", \"Art\", \"Diagram\", \"Other\"]\n",
    "subject_categories = [\"Landscape\", \"Urban\", \"Portrait\", \"Pets\", \"Wildlife\", \"Other\"]\n",
    "\n",
    "# OpenAI API Key\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc53c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_files_generator(directory: str) -> typing.Generator[str, None , None]:\n",
    "    \"\"\"\n",
    "    Recursively finds all image files in the specified directory and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory to search in.\n",
    "\n",
    "    Returns:\n",
    "        Generator[str]: paths to image files found yielded one at a time\n",
    "    \"\"\"\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp', '*.tiff']\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for extension in image_extensions:\n",
    "            for filename in fnmatch.filter(files, extension):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                yield file_path.replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = list(image_files_generator(directory = folder_to_classify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path:str) -> str:\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    This function opens an image file, reads the file, encodes it to base64, \n",
    "    and then decodes it to utf-8 format. The resulting string is returned.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: The base64 encoded string of the image file.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def decode_response(response:requests.models.Response) -> tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Decodes the response from a request.\n",
    "\n",
    "    This function takes a response from a request, extracts the content, \n",
    "    splits it into style, category, and description, and returns these as a tuple. \n",
    "    If the content does not contain all three elements, it makes assumptions \n",
    "    about the missing elements.\n",
    "\n",
    "    Args:\n",
    "        response (requests.models.Response): The response from a request to the OpenAI API\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str, str]: A tuple containing the style, category, and description.\n",
    "    \"\"\"\n",
    "    content = response.json()['choices'][0]['message']['content']\n",
    "    # split up our reqested pipe separated triplet of style|category|description\n",
    "    contents = content.split('|')\n",
    "    style = contents[0]\n",
    "    try:\n",
    "        category = contents[1]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    try:\n",
    "        description = contents[2]\n",
    "    except IndexError:\n",
    "        # if we are missing indices we cannot assume anything is correct so place what we do have in the description\n",
    "        description = contents[0]\n",
    "        style = \"unknown\"\n",
    "        category = \"unknown\"\n",
    "    return style, category, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(\n",
    "    image_path: str,\n",
    "    api_key: str|None,\n",
    "    style_categories: list[str],\n",
    "    subject_categories: list[str]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Categorize an image based on style, subject, and description.\n",
    "\n",
    "    This function takes an image file path, an OpenAI API key, permissible style categories,\n",
    "    and permissible subject categories. It sends the image to the OpenAI API for analysis and\n",
    "    returns a pipe-separated string containing the most appropriate style, subject, and description.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): The file path to the image.\n",
    "        api_key (str): API key for authentication.\n",
    "        param style_categories (List[str]): List of permissible style categories.\n",
    "        param subject_categories (List[str]):  List of permissible subject categories.\n",
    "    \n",
    "    Returns: \n",
    "        Tuple[str, str, str]: A pipe-separated string in the format \"Style|Subject|Description\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Getting the base64 string required by the OpenAI API\n",
    "    base64_image = encode_image(image_path)\n",
    "    # compile\n",
    "\n",
    "    # compile the query to go with the image\n",
    "    text = f\"\"\"Please categorise this image.\n",
    "To do this you will return a pipe separated string of the form: \n",
    "Style|Subject|Description \n",
    "Permissible styles are: {\", \".join(style_categories)} . Pick only the most appropriate one.\n",
    "Permissible subjects are: {\", \".join(subject_categories)} . Pick only the most appropriate one.\n",
    "The description should be no more than 30 words long and should describe the picture as accurately as possible\n",
    "Return no other detail other than the 3 pipe separated items so for instance if the style was {style_categories[0]}\n",
    "and the subject was {subject_categories[0]} and the description was 'A small apple in a green bowl' you would return:\n",
    "{style_categories[0]}|{subject_categories[0]}|A small apple in a green bowl\n",
    "\"\"\"\n",
    "    \n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    # compile the openAI payload\n",
    "    payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": text\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "    }\n",
    "   \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    style, category, description = decode_response(response)\n",
    "\n",
    "    return style, category, description \n",
    "\n",
    "partial_categorise = functools.partial(\n",
    "    categorise,\n",
    "    api_key = OPENAI_API_KEY,\n",
    "    style_categories = style_categories,\n",
    "    subject_categories = subject_categories,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_image_files(image_files:list[str]) -> typing.Generator[dict[str], None , None]:\n",
    "    \"\"\"\n",
    "    Categorises a list of image files.\n",
    "\n",
    "    This function takes a list of image file paths, categorises each image, \n",
    "    and returns a list of dictionaries. Each dictionary contains the file path \n",
    "    and its corresponding categories.\n",
    "\n",
    "    Args:\n",
    "        image_files (List[str]): A list of image file paths.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: A list of dictionaries. Each dictionary contains \n",
    "        'file' (the file path) and 'categories' (the categories of the image).\n",
    "    \"\"\"\n",
    "    for image_file in image_files:\n",
    "        style, category, description = partial_categorise(image_file)\n",
    "        category_dict = {\n",
    "            'file': image_file,\n",
    "            'style': style,\n",
    "            'category': category,\n",
    "            'description': description,\n",
    "        }\n",
    "        yield category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorised_pictures = list(categorise_image_files(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pictures = pd.DataFrame(categorised_pictures)\n",
    "display(df_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results out to durable storage\n",
    "df_pictures.to_excel(folder_to_classify + \"/picture_classification.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.datetime.now()\n",
    "total_time = end_time - start_time\n",
    "print(total_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
